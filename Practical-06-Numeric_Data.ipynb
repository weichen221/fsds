{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Practical 6: Numeric Data\n",
        "\n",
        "Easing into EDA with Pandas\n",
        "\n",
        "This session is a tour-de-`pandas`; since this is Pythonâ€™s equivalent of\n",
        "the `tidyverse` meets `data.tables` it is fundamental to the data\n",
        "science ecosystem and is probably one of the most-widely used libraries\n",
        "in the language as a whole. I get [more than 286,000\n",
        "questions](https://stackoverflow.com/questions/tagged/pandas) tagged\n",
        "with pandas on StackOverflow.\n",
        "\n",
        "This week we are also going to start looking more closely at the\n",
        "**[InsideAirbnb](http://insideairbnb.com/)** data which forms the core\n",
        "of the work that we do over the rest of the term. The focus of *this*\n",
        "notebook is simple numeric data: no mapping or text dataâ€¦ yetâ€¦ and\n",
        "direct manipulation of data types, derivation of summary statistics, and\n",
        "simple plotting.\n",
        "\n",
        "We hope that you will be able to draw on the past few practical sessions\n",
        "to develop a more intuitive understanding of how to interact with pandas\n",
        "since it supports both a â€˜dictionary-of-listsâ€™ style of interaction\n",
        "*and* a methods-based style of interaction with the â€˜Data Frameâ€™.\n",
        "\n",
        "> **Important**\n",
        ">\n",
        "> Conceptually, this practical links together *all* of the preceding\n",
        "> ones; you will find data structures, classes and methods, reading CSV\n",
        "> files from a remote location, `numpy`, and more than you ever wanted\n",
        "> to know about data types in Python. Making these connections will make\n",
        "> the remainder of term much, much easier, so it might be worth\n",
        "> **revising this practical** over Reading Week so make sure it all\n",
        "> makes sense! That may include rewatching the lectures on\n",
        "> [Data](https://jreades.github.io/fsds/sessions/week6.html#pre-recorded-lectures)\n",
        "> and\n",
        "> [Pandas](https://jreades.github.io/fsds/sessions/week6.html#pre-recorded-lectures)\n",
        "\n",
        "## 1. The Importance of EDA\n",
        "\n",
        "After a few weeks getting to grips with Python, weâ€™re now going to start\n",
        "working with some real data. One of the first things that we do when\n",
        "working with any new data set is to familiarise ourselves with it. There\n",
        "are a *huge* number of ways to do this, but there are no shortcuts to:\n",
        "\n",
        "1.  Reading about the data (how it was collected, what the sample size\n",
        "    was, etc.)\n",
        "2.  Reviewing any accompanying metadata (data about the data, column\n",
        "    specs, etc.)\n",
        "3.  Looking at the data itself at the row- and column-levels\n",
        "4.  Producing descriptive statistics\n",
        "5.  Visualising the data using plots\n",
        "\n",
        "You should use *all* of these together to really understand where the\n",
        "data came from, how it was handled, and whether there are gaps or other\n",
        "problems. If youâ€™re wondering which comes first, the concept of *start\n",
        "with a chart* is always goodâ€¦ though weâ€™ve obviously not *quite* gotten\n",
        "there yet! This week we want you to get a handle on pandas itself, so\n",
        "although we will do some plotting of charts, weâ€™ll focus on 3-4 with a\n",
        "tiny bit of 5. There will be much more on plotting charts next week, and\n",
        "you should be looking into 1 and 2 yourself based on whatâ€™s been written\n",
        "both on the [Inside Airbnb web site](http://insideairbnb.com/about.html)\n",
        "and in the [suggested\n",
        "readings](https://github.com/jreades/i2p/blob/master/ref/Bibliography.md).\n",
        "\n",
        "So although they donâ€™t need to be done now, you probably want to add\n",
        "both those links to your reading list!\n",
        "\n",
        "## 2. Pandas, Conceptually\n",
        "\n",
        "> **ðŸ”— Connections**\n",
        ">\n",
        "> This is why we spent time talking about\n",
        "> [Packages](https://jreades.github.io/fsds/sessions/week3.html#pre-recorded-lectures),\n",
        "> [Methods](https://jreades.github.io/fsds/sessions/week4.html#pre-recorded-lectures)\n",
        "> [Classes](https://jreades.github.io/fsds/sessions/week4.html#pre-recorded-lectures)â€¦\n",
        "> because now weâ€™re going to be making *intensive* use of them.\n",
        "\n",
        "Pandas can do a *lot*, and you might be feeling a little intimidated by\n",
        "this, but hereâ€™s the thing: we were already writing something like\n",
        "pandas from scratch! Thatâ€™s because pandas takes a **column-view of\n",
        "data** in the same way that our **Dictionary-of-Lists** did, itâ€™s just\n",
        "that itâ€™s got a lot more features than our â€˜simpleâ€™ tool did. Thatâ€™s why\n",
        "the documentation is so much more forbidding and why pandas is so much\n",
        "more powerful.\n",
        "\n",
        "But at its heart, a pandas `Data Frame` (`df` for short) is a collection\n",
        "of `Data Series` objects (i.e.Â columns) with an index. Each Series is\n",
        "like one of our column-lists from the last notebook. And the `df` is\n",
        "like the dictionary that held the data together. So youâ€™ve seen this\n",
        "before and you already *know* whatâ€™s going onâ€¦ or at least you now have\n",
        "an *analogy* that you can use to make sense of pandas:\n",
        "\n",
        "``` default\n",
        "myDataFrame = {\n",
        "    '<column_name_1>': <Series_1>,\n",
        "    '<column_name_2>': <Series_2>,\n",
        "    '<column_name_3>': <Series_3>\n",
        "}\n",
        "```\n",
        "\n",
        "And pandas gives us two ways to access that data:\n",
        "\n",
        "1.  Using a method syntax: `myDataFrame.column_name_1`\n",
        "2.  Using a dictionary syntax: `myDataFrame['column_name_1']`[1]\n",
        "\n",
        "Depending on which syntax you prefer, you can use these interchangeably.\n",
        "The only times you *have* to choose one over the other are:\n",
        "\n",
        "-   Assignment (e.g.Â `myDataFrame['column_name_1'] = ...`);\n",
        "-   Columns with spaces in their names\n",
        "    (e.g.Â `myDataFrame['Column Name 1')`).\n",
        "\n",
        "There are [numerous](http://lmgtfy.com/?q=introduction+to+pandas+python)\n",
        "useful introductions; [one of our\n",
        "favourites](http://www.gregreda.com/2013/10/26/intro-to-pandas-data-structures/)\n",
        "is from Greg Reda, and there are some [good\n",
        "videos](https://youtu.be/TSsSWuhBpmY) on [our YouTube\n",
        "channel](https://www.youtube.com/playlist?list=PLJ5Y5hxm-0W7rOOYBHf6KC6QNnWOi09kh).\n",
        "And of course, thereâ€™s [TONS of\n",
        "stuff](http://stackoverflow.com/questions/tagged/pandas) on\n",
        "StackOverflow. If you want an actual physical book, you might try\n",
        "[McKinney (2017)](http://shop.oreilly.com/product/0636920050896.do).\n",
        "\n",
        "## 3. Reading Data\n",
        "\n",
        "Itâ€™s always sensible to import the packages you need at the top of the\n",
        "notebook:\n",
        "\n",
        "1.  Because it lets everyone know what they need to have installed to\n",
        "    run your code.\n",
        "2.  Itâ€™s easy to run this and then skip further down the notebook if you\n",
        "    have already done *some* of the work and saved an intermediate\n",
        "    output.\n",
        "\n",
        "So in this practical we need:\n",
        "\n",
        "[1] This is also how `[polars](https://pola.rs/)` does things"
      ],
      "id": "74e57325-93d2-4263-a305-ddba7f669b15"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "id": "4f27ebe8"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "One thing you will really want to bookmark is [the official\n",
        "documentation](http://pandas.pydata.org/pandas-docs/stable/) since you\n",
        "will undoubtedly need to refer to it fairly regularly. *Note*: this link\n",
        "is to the most recent release. Over time there will be updates published\n",
        "and you *may* find that you no longer have the most up-to-date version.\n",
        "If you find that you are now using an older version of pandas and the\n",
        "methods have changed then youâ€™ll need to track down the *specific*\n",
        "version of the documentation that you need from the [home\n",
        "page](http://pandas.pydata.org).\n",
        "\n",
        "You can always check what version you have installed like this:"
      ],
      "id": "e5dc2db5-e318-4c12-a255-9a6047b7e493"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.3.2"
          ]
        }
      ],
      "source": [
        "print(pd.__version__)"
      ],
      "id": "291bf31c"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "> **Tip**\n",
        ">\n",
        "> The `<package_name>.__version__` approach isnâ€™t guaranteed to work\n",
        "> with *every* package, but it will work with most of them. Remember\n",
        "> that variables and methods starting and ending with â€˜`__`â€™ are\n",
        "> **private** and any interaction with them should be approached very,\n",
        "> very carefully.\n",
        "\n",
        "### 3.1 Reading Remote Data\n",
        "\n",
        "> **Difficulty: Low (this time around).**\n",
        "\n",
        "You will need to do several things here to read the remote, compressed\n",
        "CSV file specified by `url` into a data frame called `df`. Setting\n",
        "`low_memory=False` ensures that pandas will try to load the entire data\n",
        "set *before* guessing the data type for each column! Obviously, with\n",
        "very large files this is probably a bad idea and itâ€™s possible to force\n",
        "a particular column type while readng in the data as well.\n",
        "\n",
        "> For larger data sets there is [Polars](https://pola.rs/),\n",
        "> [DuckDB](https://duckdb.org/), and platforms like\n",
        "> [Dask](https://dask.org/) (see, eg,\n",
        "> [this](https://towardsdatascience.com/why-and-how-to-use-dask-with-big-data-746e34dac7c3))\n",
        "> and\n",
        "> [beyond](https://towardsdatascience.com/scaling-pandas-comparing-dask-ray-modin-vaex-and-rapids-c74c85a4e59c).\n",
        "\n",
        "#### 3.1.1 Parameterising Files\n",
        "\n",
        "Anyway, hereâ€™s where to find the data:"
      ],
      "id": "e53b1f81-b48b-4a47-906f-843b0068fc4a"
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Set download URL\n",
        "ymd  = '20250615'\n",
        "city = 'London'\n",
        "host = 'https://orca.casa.ucl.ac.uk'\n",
        "url  = f'{host}/~jreades/data/{ymd}-{city}-listings.csv.gz'"
      ],
      "id": "e31eaaf6"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 3.1.2 Reading CSV with Pandas\n",
        "\n",
        "Now, what goes into the `read_csv` function below?\n",
        "\n",
        "##### 3.1.2.1 Question"
      ],
      "id": "e999f631-95fe-4e51-adaf-9bf63420d701"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# your code here\n",
        "df = pd.read_csv(??, compression='gzip', low_memory=False)\n",
        "print(f\"Data frame is {df.shape[0]:,} x {df.shape[1]}\")"
      ],
      "id": "bd7c1d69-ee90-4128-bce8-cbc09c32b45b"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "You should get a data frame containing 79 columns and 96,651 rows of\n",
        "data.\n",
        "\n",
        "## 4. Inspecting the Data Frame\n",
        "\n",
        "> **Difficulty: Low.**\n",
        "\n",
        "Letâ€™s get a general sense of the data by printing out information\n",
        "*about* the data frame. There are several ways to do this (and weâ€™ll see\n",
        "another futher on):\n",
        "\n",
        "-   `df.describe(percentiles=None, include=None, exclude=None, datetime_is_numeric=False)`\n",
        "    â€“ descriptive stats for all **numeric** columns\n",
        "-   `df.info(verbose=None, buf=None, max_cols=None, memory_usage=None, show_counts=None)`\n",
        "    â€“ summarises all columns, but without distribution information\n",
        "-   `df.memory_usage(index=True, deep=True)` â€“ memory usage details\n",
        "    about each column (can be quite slow as itâ€™s doing a *lot* of\n",
        "    digging)\n",
        "\n",
        "##### 4.0.0.1 Question\n",
        "\n",
        "What is another term for the 0.5 percentile?\n",
        "\n",
        "#### 4.0.1 Describing\n",
        "\n",
        "Describing a data frame provides general information about *numeric*\n",
        "columns, such as the median, IQR, or number of discrete values.\n",
        "\n",
        "So to show the 5th and 95th percentiles you need to pass an argument to\n",
        "`describe` to override the default report from pandas. Notice here how\n",
        "we can **subselect columns** using a list:\n",
        "`df[ [<names of selected columns>] ]`!\n",
        "\n",
        "##### 4.0.1.1 Question"
      ],
      "id": "40303be1-0848-4fb3-bcf6-76b5c3a4a339"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df[\n",
        "    ['latitude', 'longitude', 'accommodates', 'bathrooms', 'bedrooms', 'beds']\n",
        "].describe(percentiles=[??])"
      ],
      "id": "5a45460a-2b20-45d0-b0bf-573b51b4c4b6"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 4.0.2 Info\n",
        "\n",
        "The `info` method provides a more system-oriented view of the data\n",
        "frame, helping you to understand what each column is composed of, how\n",
        "many NAs there might be, and some high-level (but often incomplete) data\n",
        "on performance.\n",
        "\n",
        "``` python\n",
        "df.info(verbose=True)\n",
        "```\n",
        "\n",
        "    <class 'pandas.core.frame.DataFrame'>\n",
        "    RangeIndex: 96651 entries, 0 to 96650\n",
        "    Data columns (total 79 columns):\n",
        "     #   Column                                        Non-Null Count  Dtype  \n",
        "    ---  ------                                        --------------  -----  \n",
        "     0   id                                            96651 non-null  int64  \n",
        "     1   listing_url                                   96651 non-null  object \n",
        "     2   scrape_id                                     96651 non-null  int64  \n",
        "     3   last_scraped                                  96651 non-null  object \n",
        "     4   source                                        96651 non-null  object \n",
        "     5   name                                          96651 non-null  object \n",
        "     6   description                                   93806 non-null  object \n",
        "     7   neighborhood_overview                         41983 non-null  object \n",
        "     8   picture_url                                   96642 non-null  object \n",
        "     9   host_id                                       96651 non-null  int64  \n",
        "     10  host_url                                      96651 non-null  object \n",
        "     11  host_name                                     96611 non-null  object \n",
        "     12  host_since                                    96613 non-null  object \n",
        "     13  host_location                                 73323 non-null  object \n",
        "     14  host_about                                    49314 non-null  object \n",
        "     15  host_response_time                            63627 non-null  object \n",
        "     16  host_response_rate                            63627 non-null  object \n",
        "     17  host_acceptance_rate                          69036 non-null  object \n",
        "     18  host_is_superhost                             94828 non-null  object \n",
        "     19  host_thumbnail_url                            96613 non-null  object \n",
        "     20  host_picture_url                              96613 non-null  object \n",
        "     21  host_neighbourhood                            46291 non-null  object \n",
        "     22  host_listings_count                           96613 non-null  float64\n",
        "     23  host_total_listings_count                     96613 non-null  float64\n",
        "     24  host_verifications                            96613 non-null  object \n",
        "     25  host_has_profile_pic                          96613 non-null  object \n",
        "     26  host_identity_verified                        96613 non-null  object \n",
        "     27  neighbourhood                                 41984 non-null  object \n",
        "     28  neighbourhood_cleansed                        96651 non-null  object \n",
        "     29  neighbourhood_group_cleansed                  0 non-null      float64\n",
        "     30  latitude                                      96651 non-null  float64\n",
        "     31  longitude                                     96651 non-null  float64\n",
        "     32  property_type                                 96651 non-null  object \n",
        "     33  room_type                                     96651 non-null  object \n",
        "     34  accommodates                                  96651 non-null  int64  \n",
        "     35  bathrooms                                     62730 non-null  float64\n",
        "     36  bathrooms_text                                96502 non-null  object \n",
        "     37  bedrooms                                      84071 non-null  float64\n",
        "     38  beds                                          62676 non-null  float64\n",
        "     39  amenities                                     96651 non-null  object \n",
        "     40  price                                         62684 non-null  object \n",
        "     41  minimum_nights                                96651 non-null  int64  \n",
        "     42  maximum_nights                                96651 non-null  int64  \n",
        "     43  minimum_minimum_nights                        96651 non-null  int64  \n",
        "     44  maximum_minimum_nights                        96651 non-null  int64  \n",
        "     45  minimum_maximum_nights                        96651 non-null  int64  \n",
        "     46  maximum_maximum_nights                        96651 non-null  int64  \n",
        "     47  minimum_nights_avg_ntm                        96651 non-null  float64\n",
        "     48  maximum_nights_avg_ntm                        96651 non-null  float64\n",
        "     49  calendar_updated                              0 non-null      float64\n",
        "     50  has_availability                              92188 non-null  object \n",
        "     51  availability_30                               96651 non-null  int64  \n",
        "     52  availability_60                               96651 non-null  int64  \n",
        "     53  availability_90                               96651 non-null  int64  \n",
        "     54  availability_365                              96651 non-null  int64  \n",
        "     55  calendar_last_scraped                         96651 non-null  object \n",
        "     56  number_of_reviews                             96651 non-null  int64  \n",
        "     57  number_of_reviews_ltm                         96651 non-null  int64  \n",
        "     58  number_of_reviews_l30d                        96651 non-null  int64  \n",
        "     59  availability_eoy                              96651 non-null  int64  \n",
        "     60  number_of_reviews_ly                          96651 non-null  int64  \n",
        "     61  estimated_occupancy_l365d                     96651 non-null  int64  \n",
        "     62  estimated_revenue_l365d                       62684 non-null  float64\n",
        "     63  first_review                                  71487 non-null  object \n",
        "     64  last_review                                   71487 non-null  object \n",
        "     65  review_scores_rating                          71487 non-null  float64\n",
        "     66  review_scores_accuracy                        71472 non-null  float64\n",
        "     67  review_scores_cleanliness                     71478 non-null  float64\n",
        "     68  review_scores_checkin                         71443 non-null  float64\n",
        "     69  review_scores_communication                   71466 non-null  float64\n",
        "     70  review_scores_location                        71442 non-null  float64\n",
        "     71  review_scores_value                           71442 non-null  float64\n",
        "     72  license                                       0 non-null      float64\n",
        "     73  instant_bookable                              96651 non-null  object \n",
        "     74  calculated_host_listings_count                96651 non-null  int64  \n",
        "     75  calculated_host_listings_count_entire_homes   96651 non-null  int64  \n",
        "     76  calculated_host_listings_count_private_rooms  96651 non-null  int64  \n",
        "     77  calculated_host_listings_count_shared_rooms   96651 non-null  int64  \n",
        "     78  reviews_per_month                             71487 non-null  float64\n",
        "    dtypes: float64(21), int64(24), object(34)\n",
        "    memory usage: 58.3+ MB\n",
        "\n",
        "You should get that the data frame has a mix of `float64`, `int`, and\n",
        "`object` (text) columns and that some columns contain many nulls. You\n",
        "will also get an *estimate* of memory usage that may differ\n",
        "substantially from the more complete picture provided below, which\n",
        "suggests a â€˜trueâ€™ value of 369MB.\n",
        "\n",
        "#### 4.0.3 Memory Usage\n",
        "\n",
        "If you really need to get into the â€˜weedsâ€™ and profile your data frame\n",
        "because you are crashing Python and seeing messages about â€˜core dumpedâ€™,\n",
        "or experiencing appallingly poor performance (allowing for the amount of\n",
        "data youâ€™ve just loaded!), then `memory_usage` is the way to go:"
      ],
      "id": "191d5f8f-a4c1-441b-8aea-d61a68344c0c"
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "df.memory_usage(index=True, deep=True)"
      ],
      "id": "816ef7f4"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "    Index                                               132\n",
        "    id                                               773208\n",
        "    listing_url                                     8915865\n",
        "    scrape_id                                        773208\n",
        "    last_scraped                                    5702409\n",
        "                                                     ...   \n",
        "    calculated_host_listings_count                   773208\n",
        "    calculated_host_listings_count_entire_homes      773208\n",
        "    calculated_host_listings_count_private_rooms     773208\n",
        "    calculated_host_listings_count_shared_rooms      773208\n",
        "    reviews_per_month                                773208\n",
        "    Length: 80, dtype: int64\n",
        "\n",
        "You should see that the data frame uses 387,420,178 bytes of memory, but\n",
        "the *really* important thing to note here is the difference between\n",
        "`string` and other types of data: keeping data as raw strings (instead\n",
        "of converting to categories, for instance) uses up a *lot* more memory\n",
        "and this can have a huge impact on the performance of your code.\n",
        "\n",
        "#### 4.0.4 Printing the Columns\n",
        "\n",
        "Finally, I find it *very* useful to be able to quickly print out a list\n",
        "of the **columns** without all of the details shown above. You just need\n",
        "to *print* the *columns* as a *list*:"
      ],
      "id": "9944ea3d-8395-4ea8-971c-db98c333697d"
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['id', 'listing_url', 'scrape_id', 'last_scraped', 'source', 'name', 'description', 'neighborhood_overview', 'picture_url', 'host_id', 'host_url', 'host_name', 'host_since', 'host_location', 'host_about', 'host_response_time', 'host_response_rate', 'host_acceptance_rate', 'host_is_superhost', 'host_thumbnail_url', 'host_picture_url', 'host_neighbourhood', 'host_listings_count', 'host_total_listings_count', 'host_verifications', 'host_has_profile_pic', 'host_identity_verified', 'neighbourhood', 'neighbourhood_cleansed', 'neighbourhood_group_cleansed', 'latitude', 'longitude', 'property_type', 'room_type', 'accommodates', 'bathrooms', 'bathrooms_text', 'bedrooms', 'beds', 'amenities', 'price', 'minimum_nights', 'maximum_nights', 'minimum_minimum_nights', 'maximum_minimum_nights', 'minimum_maximum_nights', 'maximum_maximum_nights', 'minimum_nights_avg_ntm', 'maximum_nights_avg_ntm', 'calendar_updated', 'has_availability', 'availability_30', 'availability_60', 'availability_90', 'availability_365', 'calendar_last_scraped', 'number_of_reviews', 'number_of_reviews_ltm', 'number_of_reviews_l30d', 'availability_eoy', 'number_of_reviews_ly', 'estimated_occupancy_l365d', 'estimated_revenue_l365d', 'first_review', 'last_review', 'review_scores_rating', 'review_scores_accuracy', 'review_scores_cleanliness', 'review_scores_checkin', 'review_scores_communication', 'review_scores_location', 'review_scores_value', 'license', 'instant_bookable', 'calculated_host_listings_count', 'calculated_host_listings_count_entire_homes', 'calculated_host_listings_count_private_rooms', 'calculated_host_listings_count_shared_rooms', 'reviews_per_month']"
          ]
        }
      ],
      "source": [
        "print(df.columns.to_list())"
      ],
      "id": "d8481dc5"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "You should get a list showing every single column. If you get\n",
        "`Index(['id', 'listing_url',...], dtype='object')` then you have printed\n",
        "the column *index* object and you to need to tell the object to convert\n",
        "its output **to a list** (*hint*: Google).\n",
        "\n",
        "## 5. Managing Your Data\n",
        "\n",
        "When starting out itâ€™s common to think in terms of there being one input\n",
        "(the raw data) and one output (the results) to an analysis. In practice,\n",
        "you typically will have many intermediate outputs used as â€˜milestonesâ€™\n",
        "in the overall analysis:\n",
        "\n",
        "-   You might have a â€˜canonicalâ€™ data file that has dealt with\n",
        "    formatting issues and converted the columns to appropriate data\n",
        "    types.\n",
        "-   You might have a â€˜cleanâ€™ data file that has dealt with observations\n",
        "    that seem to be incomplete or otherwise improperly formatted.\n",
        "-   You might generate subsets by region or area.\n",
        "-   You might produce an â€˜analyticalâ€™ or â€˜finalâ€™ data set appropriate to\n",
        "    a specific analysis.\n",
        "\n",
        "The purpose of the intermediate outputs is to accelerate each cycle in\n",
        "your development work: if you are re-running the *entire* analytics\n",
        "pipeline *every* time you make a small change at the tail-end of your\n",
        "processing pipeline then you will be drinking a lot of tea because most\n",
        "of your time will be spent watching the computer churn away at the data.\n",
        "Itâ€™s also common to receive regular updates of data sets\n",
        "(e.g.Â InsideAirbnb data is updated rouhgly every six months, while Land\n",
        "Registryâ€™s Price Paid Data for the UK is updated monthly) and youâ€™ll\n",
        "need to know which release youâ€™re working with (i.e.Â have I already\n",
        "processed the September data???).\n",
        "\n",
        "So we try to get ahead of all this by anticipating that files will be\n",
        "â€˜versionedâ€™. I do not mean that youâ€™ll put files in Git, but that youâ€™ll\n",
        "need a way to track â€˜provenanceâ€™ and â€˜stage of analysisâ€™ in where and\n",
        "how you save your data. But we also donâ€™t want to mindlessly delete the\n",
        "original, â€˜rawâ€™ data: I always prefer to keep the original data set\n",
        "handy since I almost always discover that there are fields I didnâ€™t\n",
        "realise I needed when I started my work.\n",
        "\n",
        "So my approach to coding is usually:\n",
        "\n",
        "1.  Download the raw file and save it locally in a `data/raw` directory.\n",
        "2.  Load the first `nrows` of data so that I can quickly:\n",
        "    -   Check that the specification matches the data and select\n",
        "        columns/rows accordingly.\n",
        "    -   Identify obviously invalid rows/columns and investigate further.\n",
        "    -   Check the code to fix data types and (where relevant) values\n",
        "        works.\n",
        "    -   Write this new, smaller file ($m` << m$ and $n` << n$) out to a\n",
        "        `data/clean` or `data/canonical` directory (depending on whether\n",
        "        formatting the columns is so complex or takes so long on a large\n",
        "        data set that dealing with data types needs to be separated out\n",
        "        from actual cleaning).\n",
        "    -   Test out some initial ideas for further analysis.\n",
        "3.  Re-run the code (remove the `nrows` limit) using the full data set.\n",
        "\n",
        "So you might end up with something a bit like this (or this could be\n",
        "overkill):\n",
        "\n",
        "``` default\n",
        "|\n",
        "|--project/\n",
        "|  |--code/\n",
        "|     |--extract/\n",
        "|     |--canonicalise/\n",
        "|     |--clean/\n",
        "|     |--analyse/\n",
        "|  |--data/\n",
        "|     |--raw/\n",
        "|        |--2025/\n",
        "|        |--2024/\n",
        "|     |--clean/\n",
        "|        |--2025/\n",
        "|        |--2024/\n",
        "|  |--docs/\n",
        "|     |--refs/\n",
        "|     |--code/\n",
        "|     |--data/\n",
        "|  |--conf \n",
        "```\n",
        "\n",
        "There is even a coding library called\n",
        "[cookiecutter](https://www.cookiecutter.io/) that tries to help research\n",
        "groups and companies standardise how they manage their code and data.\n",
        "\n",
        "> **Difficulty: Moderate**\n",
        ">\n",
        "> Although the code here is simple, the logic is not.\n",
        "\n",
        "### 5.1 File Names\n",
        "\n",
        "You should always be looking for ways to *avoid* hard-coding values that\n",
        "might change over time, especially those linked to the date of the data\n",
        "file.\n",
        "\n",
        "In this case you might try to work out how to make it easy to update the\n",
        "code to download the latest file. For instance, if the file looks like\n",
        "`20250910-listings.csv.gz` then I might well specify the `url` as\n",
        "`{date}-listings.csv.gz` or `{year}{month}{day}-listings.csv.gz` and set\n",
        "up the variables that I need beforehand, possibly in a separate\n",
        "â€˜configurationâ€™ file that I read in at the start.\n",
        "\n",
        "Using parameters makes it easier to write robust code that doesnâ€™t have\n",
        "unwanted side-effects. Hereâ€™s a common one: you write code to download\n",
        "and process a file named `20251111-data.csv.gz`. You save the outputs to\n",
        "`clean-data.csv.gz`.\n",
        "\n",
        "##### 5.1.0.1 Question\n",
        "\n",
        "What happens when your boss asks you to process `20251211-data.csv.gz`?\n",
        "\n",
        "### 5.2 File Saving\n",
        "\n",
        "> **Difficulty: Low**\n",
        "\n",
        "Now save the file somewhere local so that you donâ€™t have to keep\n",
        "downloading 40MB of compressed data every time you want to start the\n",
        "practical. Weâ€™ll be using this data for the rest of term, so you might\n",
        "as well save yourself some time and bandwidth! Weâ€™ll talk more about\n",
        "data processing pipelines over the course of the term, but Iâ€™d suggest\n",
        "putting this data set into a `data/raw` folder because then you can have\n",
        "directories like `data/clean` and `data/analytical` as you move through\n",
        "the process of cleaning and prepping your data for analysis."
      ],
      "id": "efa7f2a0-3f35-4b56-9249-65c246d46f60"
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing to: data/raw/20250615-London-listings.csv.gz"
          ]
        }
      ],
      "source": [
        "path = Path(f'data/raw/{Path(url).name}') # What does this do?\n",
        "print(f\"Writing to: {path}\")"
      ],
      "id": "01db1fff"
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "if not path.parent.exists(): # And what does *this* do?\n",
        "    print(f\"Creating {path.parent}\")\n",
        "    path.parent.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "if not path.exists():  \n",
        "    df.to_csv(path, index=False)\n",
        "    print(\"Done.\")"
      ],
      "id": "32120a95"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 5.3 File Loading\n",
        "\n",
        "Now letâ€™s write something that will allow us to more quickly write our\n",
        "code and validate the results in exploratory phase. For simplicity Iâ€™ve\n",
        "called this â€˜testingâ€™, but you could also think of it as â€˜devâ€™ mode.\n",
        "What we want is to be able to easily swap between testing and\n",
        "operational contexts using a â€˜switchâ€™ (typically, a Boolean value) and\n",
        "limit the data load in testing mode.\n",
        "\n",
        "To achieve this you could set pandas to:\n",
        "\n",
        "-   Load only the first 10,000 rows using `nrows` *if* we are testing\n",
        "-   Use the columns specified in `cols`\n",
        "-   Allow pandas to load the entire data set before deciding on the\n",
        "    column type by setting `low_memory` appropriately.\n",
        "\n",
        "#### 5.3.1 Row Subsetting\n",
        "\n",
        "Letâ€™s tackle the *rows* problem first:\n",
        "\n",
        "##### 5.3.1.1 Question"
      ],
      "id": "a1af2eb6-33d2-461b-8ef7-47c2f75a6ad3"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "testing = True\n",
        "\n",
        "if testing:\n",
        "    df = pd.read_csv(path, \n",
        "                low_memory=??, ??)\n",
        "else:\n",
        "    df = pd.read_csv(path, \n",
        "                low_memory=??)\n",
        "\n",
        "print(f\"Data frame is {df.shape[0]:,} x {df.shape[1]}\")"
      ],
      "id": "03e7ee19-66df-4fef-9545-f9028f6244ff"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "So notice how this code deliberately works the same for either testing\n",
        "*or* operational execution â€“ we just flip between the option by changing\n",
        "the `testing` variable from `True` to `False`!\n",
        "\n",
        "To make this more robust and useful we could use this `testing` variable\n",
        "*throughout* our code if we wanted to change other behaviours based on\n",
        "development/deployment context. The state of the switch could then be\n",
        "set globally using an external configuration file (usually just called a\n",
        "â€˜conf fileâ€™). The easiest way to do this is to have a `conf.py` which\n",
        "contains your global parameters and then every script or notebook file\n",
        "reads in the configuration and sets these variables.\n",
        "\n",
        "Something like:"
      ],
      "id": "51070821-c91c-4f9c-bdb9-9b0b41ce5826"
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "testing = False"
      ],
      "id": "f1eda834"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "And:"
      ],
      "id": "1f76ed1e-87ce-4105-9e88-ce865e1e5055"
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "from conf import *"
      ],
      "id": "493ee855"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 5.3.2 Column Subsetting\n",
        "\n",
        "Now letâ€™s tackle the column problemâ€¦ In order to avoid having to load\n",
        "lots of data that we arenâ€™t sure we need yet, we can restrict the\n",
        "columns that we load. We got `cols` below by copying the output of\n",
        "(`df.columns.to_list()` and then removing the fields that we thought we\n",
        "*werenâ€™t* interested in."
      ],
      "id": "56c7a0fe-c07c-478f-9996-c8bc91d413de"
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cols contains 34 columns."
          ]
        }
      ],
      "source": [
        "cols = ['id', 'listing_url', 'last_scraped', 'name', \n",
        "    'description', 'host_id', 'host_name', 'host_since', \n",
        "    'host_location', 'host_about', 'host_is_superhost', \n",
        "    'host_listings_count', 'host_total_listings_count', \n",
        "    'host_verifications', 'latitude', 'longitude', \n",
        "    'property_type', 'room_type', 'accommodates', \n",
        "    'bathrooms', 'bathrooms_text', 'bedrooms', 'beds', \n",
        "    'amenities', 'price', 'minimum_nights', 'maximum_nights', \n",
        "    'availability_365', 'number_of_reviews', \n",
        "    'first_review', 'last_review', 'review_scores_rating', \n",
        "    'license', 'reviews_per_month']\n",
        "print(f\"Cols contains {len(cols)} columns.\")"
      ],
      "id": "7e4c4977"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "So letâ€™s extend our previous answer\n",
        "\n",
        "##### 5.3.2.1 Question"
      ],
      "id": "b860f428-b47d-4919-b894-966ae657053c"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "testing = True\n",
        "\n",
        "if testing:\n",
        "    df = pd.read_csv(path, \n",
        "                low_memory=False, nrows=10000, ??)\n",
        "else:\n",
        "    df = pd.read_csv(path, \n",
        "                low_memory=False, ??)\n",
        "\n",
        "print(f\"Data frame is {df.shape[0]:,} x {df.shape[1]}\")"
      ],
      "id": "9d420af7-f976-46ae-b18a-08de90e7e0c4"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 5.4 Releasing Memory\n",
        "\n",
        "Two risks when working with Jupyter notebooks are:\n",
        "\n",
        "1.  You have run code in an order *other* than the order shown in the\n",
        "    notebook; or\n",
        "2.  You have made edits to code but *not* re-run the changed code.\n",
        "\n",
        "So youâ€™re still working from code that is no longer visible or where the\n",
        "a step (or five) has been missed/changed since you ran it! When that\n",
        "happens you can get *very* confusing issues because what you *see*\n",
        "doesnâ€™t square with what the computer has *executed*. To resolve this\n",
        "without having to re-run the entire notebook (though that can *also* be\n",
        "a good choice!) you might want to â€˜deleteâ€™ the current object and\n",
        "re-load or re-run the relevant data or code."
      ],
      "id": "5b07e1ef-c243-4914-b176-56ec503b8d45"
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [],
      "source": [
        "del(df)"
      ],
      "id": "d71f08c3"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "So we use `del(df)` to ensure that we arenâ€™t accidentally using the\n",
        "â€˜oldâ€™ data frame. But another good reason to delete data youâ€™re no\n",
        "longer using is to free up memory.\n",
        "\n",
        "## 6. Using Indexes\n",
        "\n",
        "So letâ€™s start over from the saved data:"
      ],
      "id": "3d5c1f2c-cfbc-4afa-b92d-a187e78dae54"
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [],
      "source": [
        "df = pd.read_csv(path, low_memory=False, usecols=cols)"
      ],
      "id": "232085b2"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "When we use the `[[...]]` syntax weâ€™re taking a short-cut through the\n",
        "data by column (keeping all rows). The *full* syntax is\n",
        "`df[<row_selection>,<col_selection>]`. Only when we *donâ€™t* specify both\n",
        "does it then default to `df[<col_selection>]`.\n",
        "\n",
        "To make the most of pandas you will need to get to grips with the logic\n",
        "than underpins this syntax. This is embedded in the idea of there being\n",
        "row and column indexes. These are *like* the columns `A`..`ZZ` and the\n",
        "rows `1`..$n$ in Excel. As youâ€™ll have seen in [the\n",
        "video](https://jreades.github.io/fsds/sessions/week6.html#pre-recorded-lectures),\n",
        "these arenâ€™t considered *data*, they are ways to *access the data*.\n",
        "Unlike Excel, while every data frame must *have* an index, in pandas you\n",
        "can â€˜promoteâ€™ or â€˜demoteâ€™ any column to be used *as* an index.\n",
        "\n",
        "The **default row index** is just the row number and this will be\n",
        "created for you if you donâ€™t specify something else when you create the\n",
        "data frame. The **default column index** is created from a fileâ€™s column\n",
        "names (works for many types of data) but you can also change these at\n",
        "any time.\n",
        "\n",
        "### 6.1 Numeric Indexing\n",
        "\n",
        "You can always access rows and columns by their **integer location** as\n",
        "if it is a 2D list and you want to access the 3rd to 5th columns and the\n",
        "9th to 425th rows. So if you remember that `iloc` means youâ€™re using the\n",
        "index location that will help you to work out whatâ€™s going on.\n",
        "\n",
        "So can you read this:"
      ],
      "id": "b9fe55c8-cf02-4fb7-aeda-33d9ccabb5c5"
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "output_type": "display_data",
          "metadata": {},
          "data": {
            "text/html": [
              "\n",
              "</div>"
            ]
          }
        }
      ],
      "source": [
        "df.iloc[\n",
        "    4552:4557, # <- rows\n",
        "    14:19      # <- columns\n",
        "]"
      ],
      "id": "410dbcbf"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Weâ€™re accessing the 4552nd through 4556th rows, and the 14th through\n",
        "18th columns.\n",
        "\n",
        "### 6.2 Label Indexing\n",
        "\n",
        "Where it can get confusing is when you see this:"
      ],
      "id": "e98d9e9a-89c7-4a27-8392-8ce406a8ae4f"
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "output_type": "display_data",
          "metadata": {},
          "data": {
            "text/html": [
              "\n",
              "</div>"
            ]
          }
        }
      ],
      "source": [
        "df.loc[\n",
        "    4552:4557,\n",
        "    ['latitude','longitude','property_type','room_type','price']\n",
        "]"
      ],
      "id": "7bb371e6"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This code *seems* similar, but why does this use `loc` and not `iloc`,\n",
        "and why doesnâ€™t it actually return the same data??? In this case, the\n",
        "**index** (the numbers down the left-hand side in bold) is numeric, so\n",
        "we can treat it as either a *label* (which allows us to use `df.loc`)\n",
        "*or* a list-type index (which allows us to use `df.iloc`). So with `loc`\n",
        "the value `4557` is treated as a â€˜keyâ€™ so itâ€™s retrieved, whereas with\n",
        "`.iloc` itâ€™s treated like a list index accessed with `range` and so\n",
        "*isnâ€™t* returned. Itâ€™s a bit weird, but hopefully makes *some* sense\n",
        "now.\n",
        "\n",
        "### 6.3 Non-numeric Indexes\n",
        "\n",
        "Notice the change in indexing because â€˜listing_urlâ€™ is no longer a\n",
        "column, itâ€™s the index now!"
      ],
      "id": "9c0172f0-43d0-484f-ba9e-5740cdee1e64"
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "output_type": "display_data",
          "metadata": {},
          "data": {
            "text/html": [
              "\n",
              "</div>"
            ]
          }
        }
      ],
      "source": [
        "df.set_index('listing_url').iloc[0:3,13:18] "
      ],
      "id": "113c3c4a"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Notice how this works differently if we specify a **non-numeric index**:"
      ],
      "id": "54d62f72-f287-4126-83d0-0c73631392b6"
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "output_type": "display_data",
          "metadata": {},
          "data": {
            "text/html": [
              "\n",
              "</div>"
            ]
          }
        }
      ],
      "source": [
        "df.set_index('listing_url').loc[\n",
        "    :, # <- Special syntax that means 'all rows' (or all columns)\n",
        "    ['latitude','longitude','property_type','room_type','accommodates']\n",
        "].head(3)"
      ],
      "id": "45495d31"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "> **Caution**\n",
        ">\n",
        "> Itâ€™s vital that you understand how this code *works*. By which I mean\n",
        "> *why* it does something at all, not exactly how to use `loc` and\n",
        "> `iloc` (though that is also useful).\n",
        ">\n",
        "> `df.set_index(...)` changes the index from the default row number to\n",
        "> another field in the data frame. This operation *returns* a new data\n",
        "> frame with `listing_url` as its index. Because set index returned a\n",
        "> data frame, we can simply add *another* method call (`iloc` or `loc`)\n",
        "> on to the end of that line and *it* returns a new data frame in turn!\n",
        ">\n",
        "> The fact that each operation returns a new data frame (or data series)\n",
        "> is why you can even do this:\n",
        ">\n",
        "> ``` python\n",
        ">     df.set_index('listing_url').iloc[0:3].latitude.mean()\n",
        "> ```\n",
        ">\n",
        ">     np.float64(51.500523858482154)\n",
        "\n",
        "## 7. Exploring Your Data\n",
        "\n",
        "Letâ€™s start over *again* from the saved data:"
      ],
      "id": "1714020a-e391-403c-bfd9-d32867cec3ae"
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [],
      "source": [
        "df = pd.read_csv(path, low_memory=False, usecols=cols)"
      ],
      "id": "01466ff5"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 7.1 Selecting Rows\n",
        "\n",
        "> **ðŸ”— Connections**\n",
        ">\n",
        "> You will want to refer to the\n",
        "> [Randomness](https://jreades.github.io/fsds/sessions/week5.html#pre-recorded-lectures)\n",
        "> lecture to understand how we can select the *same* random sample each\n",
        "> time and to the session on\n",
        "> [Logic](https://jreades.github.io/fsds/sessions/week5.html#pre-recorded-lectures)\n",
        "> lecture to cover `NaN`s and `NA`s.\n",
        "\n",
        "> **Difficulty: Low**\n",
        "\n",
        "I often like to start my EDA by simply printing out randomly-selected\n",
        "rows to get a feel for whatâ€™s in the data. Does what I see square with\n",
        "what I read in the documentation? What does the `name` look like? What\n",
        "do I see in `last_scraped` and is it a sensible? Whatâ€™s the `id` field\n",
        "for?"
      ],
      "id": "39489ae8-ce53-46a8-a491-9496dba0cefd"
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "output_type": "display_data",
          "metadata": {},
          "data": {
            "text/html": [
              "\n",
              "<p>3 rows Ã— 34 columns</p>\n",
              "</div>"
            ]
          }
        }
      ],
      "source": [
        "df.sample(3)"
      ],
      "id": "ee6cb891"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "See if you can work out from the documentation (Google search time!) how\n",
        "to get the same â€˜randomâ€™ sample every time you re-run this code block:\n",
        "\n",
        "##### 7.1.0.1 Question"
      ],
      "id": "f4ebb9f9-2f17-4269-81a0-aee2ef4e2e1a"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df.sample(3, ??)"
      ],
      "id": "c6556352-ad61-475b-9af8-a5751c552d0e"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 7.2 Dealing with NaNs and Nulls\n",
        "\n",
        "> **Difficulty: Hard.**\n",
        ">\n",
        "> There is a *lot* going on here and you should be paying close\n",
        "> attention.\n",
        "\n",
        "If you really dig into the data you will see that a number of data types\n",
        "that arenâ€™t â€˜appropriateâ€™ for their contents: the id columns are floats;\n",
        "the dates arenâ€™t dates; thereâ€™s a boolean thatâ€™s not a booleanâ€¦ It would\n",
        "be nice to fix these!\n",
        "\n",
        "> **Note**\n",
        ">\n",
        "> I had intended to ask you to fix these by combining code from previous\n",
        "> weeks with information provided in the lecture, but it turns out that\n",
        "> the InsideAirbnb data set is *dirty*. There are a lot of `NaN` values\n",
        "> and some of these are *deeply* problematic for some of the column\n",
        "> types in pandas. There are also a number of challenges with other\n",
        "> columns so, instead, Iâ€™ve opted to show you how I would clean this\n",
        "> data as a *first pass* to get it into a format where itâ€™s tractable\n",
        "> for further cleaning.\n",
        "\n",
        "#### 7.2.1 Identifying Problem Rows\n",
        "\n",
        "The reason Iâ€™m not asking you to do this part yourselves is that it took\n",
        "me nearly an hour just to work out why I couldnâ€™t convert some of the\n",
        "columns to the right data types; then I started finding rows like these:"
      ],
      "id": "1f8cfb34-ad1e-4fe4-b1f2-3305538b3072"
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [
        {
          "output_type": "display_data",
          "metadata": {},
          "data": {
            "text/html": [
              "\n",
              "</div>"
            ]
          }
        }
      ],
      "source": [
        "df[df.price.isna()][['id','name','price','room_type']].head(4)"
      ],
      "id": "74083261"
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [
        {
          "output_type": "display_data",
          "metadata": {},
          "data": {
            "text/html": [
              "\n",
              "</div>"
            ]
          }
        }
      ],
      "source": [
        "df[df.room_type.isna()][['id','name','price','room_type']].head(4)"
      ],
      "id": "1e7ddff1"
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [
        {
          "output_type": "display_data",
          "metadata": {},
          "data": {
            "text/html": [
              "\n",
              "</div>"
            ]
          }
        }
      ],
      "source": [
        "df[~(df.price.str.startswith('$', na=False))][['id','name','price','room_type']].head(4)"
      ],
      "id": "3bb421da"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "If I had to guess, Iâ€™d say that itâ€™s the result some kind of partial\n",
        "extract/write process because there *are* elements in some of the\n",
        "problem row(s) that look right but they are in the wrong columns. So we\n",
        "can *probably* drop some of these rows, but one thing to do is look at\n",
        "the frequency of NaNs across the data frame *first*. So we need to look\n",
        "for NaNs and Nulls, but itâ€™s quite obvious that a `NaN` in the listing\n",
        "id is a basic problem and we should [drop\n",
        "these](https://chrisalbon.com/python/data_wrangling/pandas_dropping_column_and_rows/)."
      ],
      "id": "92493f8a-0d88-41f5-aefd-3371174623cf"
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [
        {
          "output_type": "display_data",
          "metadata": {},
          "data": {
            "text/html": [
              "\n",
              "</div>"
            ]
          }
        }
      ],
      "source": [
        "df[df.id.isna()][['id','name','price','room_type']]"
      ],
      "id": "41062290"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "As always, if you donâ€™t know thatâ€™s going on, break it down:\n",
        "\n",
        "-   You have seen how column works (`[[<column names>]]`), so thatâ€™s\n",
        "    just selecting the columns that we want to show;\n",
        "-   You know how row selection works (`df[<selection criteria>]`), so\n",
        "    that isnâ€™t anything really new either;\n",
        "-   So the only really new part is `df.id.isna()`: `df.id` is the `id`\n",
        "    column (we could have written this `df['id']` if we wanted) and\n",
        "    `isna()` is a test for whether or not a value is NaN.\n",
        "\n",
        "So this shows that only one row in the 10,000 row sub-sample has a NaN\n",
        "for its id.\n",
        "\n",
        "If youâ€™re not sure what the next line does, try breaking it down by\n",
        "running the inner bits before you run the `drop` command; and also try\n",
        "looking online for examples of how to use `df.drop` (e.g.Â just up\n",
        "above):"
      ],
      "id": "2b1d0c38-3831-4c26-b9f4-0c6c4e1e93fe"
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data frame contains 93,486 rows.\n",
            "Data frame contains 93,481 rows."
          ]
        }
      ],
      "source": [
        "print(f\"Data frame contains {df.shape[0]:,} rows.\")\n",
        "df.drop(df[df.id.isna()].index.array, axis=0, inplace=True)\n",
        "print(f\"Data frame contains {df.shape[0]:,} rows.\")"
      ],
      "id": "56e57288"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "With that really troublesome data out of the way, you can now turn to\n",
        "[counting NaNs or\n",
        "Nulls](https://www.delftstack.com/howto/python-pandas/how-to-count-the-nan-values-in-a-column-in-pandas-dataframe/#df.isnull.sum-method-to-count-nan-occurrences)\n",
        "in the remaining data with a view to identifying other rows that can\n",
        "probably be dropped.\n",
        "\n",
        "#### 7.2.2 Counting Nulls by Column\n",
        "\n",
        "As a starting point I would look to drop the columns that contain only\n",
        "NaNs. Remember that weâ€™ve dropped a row from the data frame so our\n",
        "maximum is now $n-1$)! Notice how this next command works:"
      ],
      "id": "b7a58701-49de-404f-8a69-3974b451dcda"
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [],
      "source": [
        "# returns a data frame with all values set to True/False according to Null status\n",
        "df.isnull() \n",
        "# counts these values by column (we'll see another option in a moment)\n",
        "df.isnull().sum(axis=0) \n",
        "# Sort results in descending order\n",
        "df.isnull().sum(axis=0).sort_values(ascending=False) "
      ],
      "id": "5d56bbeb"
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [
        {
          "output_type": "display_data",
          "metadata": {},
          "data": {
            "text/plain": [
              "license                 93481\n",
              "host_about              45684\n",
              "beds                    32197\n",
              "bathrooms               32126\n",
              "price                   32063\n",
              "first_review            24746\n",
              "reviews_per_month       24746\n",
              "last_review             24746\n",
              "review_scores_rating    24746\n",
              "host_location           21192\n",
              "bedrooms                11686\n",
              "description              3189\n",
              "dtype: int64"
            ]
          }
        }
      ],
      "source": [
        "df.isnull().sum(axis=0).sort_values(ascending=False)[:12]"
      ],
      "id": "015fe131"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The most obvious ones here are: license, host_about, beds, bathrooms."
      ],
      "id": "86da531c-1aae-48e7-8726-704a302d1434"
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [],
      "source": [
        "df.drop(columns=['license','host_about'], inplace=True)"
      ],
      "id": "2d129e55"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Because we have dropped everything `inplace` the code simply runs and\n",
        "doesnâ€™t return anything.\n",
        "\n",
        "#### 7.2.3 Counting Nulls by Row\n",
        "\n",
        "We now know that there *are* still quite a few problems, but we do still\n",
        "need a way to identify the rows that are causing most of the problems.\n",
        "\n",
        "Notice here that the change from `axis=0` to `axis=1` changes the\n",
        "â€˜directionâ€™ of the `sum` from columns to rows. And we are getting back a\n",
        "data series because the summing operation reduces it to just one column."
      ],
      "id": "7fb3abd6-becf-4fe8-9db7-67b61dc31543"
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [
        {
          "output_type": "display_data",
          "metadata": {},
          "data": {
            "text/plain": [
              "78240    23\n",
              "56508    23\n",
              "52260    23\n",
              "50162    23\n",
              "77222    23\n",
              "4801     14\n",
              "8322     14\n",
              "45832    14\n",
              "13539    14\n",
              "4684     14\n",
              "dtype: int64"
            ]
          }
        }
      ],
      "source": [
        "df.isnull().sum(axis=1).sort_values(ascending=False).head(10)"
      ],
      "id": "2bb142e4"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "So that `Series` shows how many `NaN` values there are by index value\n",
        "(i.e.Â the row number). The first column is the row id, the second is the\n",
        "number of NaNs in that row.\n",
        "\n",
        "If we save the results to a variable called `probs` (i.e.Â problems) then\n",
        "we can decide what to do next."
      ],
      "id": "b4376f5e-6b00-44bb-b250-4be7533cd8b7"
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.series.Series'>"
          ]
        },
        {
          "output_type": "display_data",
          "metadata": {},
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmMAAAGcCAYAAACV5KcsAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90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\nCGMAAAAGEcYAAAAMIowBAAAY9P8BSv8juEbiXRQAAAAASUVORK5CYII=\n"
          }
        }
      ],
      "source": [
        "probs = df.isnull().sum(axis=1)\n",
        "print(type(probs))       # Note that this has returned a series!\n",
        "probs.plot.hist(bins=30) # Oooooooh, check out what we can do with a series!"
      ],
      "id": "494afe2d"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Looking at this histogram, I would think about dropping rows missing\n",
        "more than about 5 values on the basis that they are the ones that are\n",
        "most likely be problematic. We can use the index from `probs` to select\n",
        "out the rows we want to inspect from the main data frame.\n",
        "\n",
        "Hereâ€™s another bit of code that bears unpacking:"
      ],
      "id": "3dd8ca6f-2ff6-4a77-987f-d3fb0f548935"
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "df contains 93,481 rows.\n",
            "df contains 82,856 rows."
          ]
        }
      ],
      "source": [
        "print(f\"df contains {df.shape[0]:,} rows.\")\n",
        "cutoff = 5\n",
        "df.drop(probs[probs > cutoff].index, inplace=True)\n",
        "print(f\"df contains {df.shape[0]:,} rows.\")"
      ],
      "id": "8bea2dcd"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "1.  `probs > 5`: this selects only those rows in the â€˜probsâ€™ series\n",
        "    whose value is greater than 5\n",
        "2.  `probs[...].index` returns the index values from the Series, which\n",
        "    we will then pass to the `drop` command.\n",
        "3.  `df.drop(..., inplace=True)` will then drop the rows selected by\n",
        "    `probs[probs>5].index`.\n",
        "\n",
        "## 8. Fixing Data Types\n",
        "\n",
        "When we fix the data types we are undertaking a kind of data\n",
        "â€˜profilingâ€™: working out what kind of data we are working with and how\n",
        "it should be represented at the level of observations and columns. There\n",
        "are *huge* benefits to computer memory and diskspace usage to profiling\n",
        "and, consequently, huge gains to be made in the speed of data analysis.\n",
        "\n",
        "If you want to challenge yourself, then Iâ€™d suggest trying to work out\n",
        "how to adapt what we saw in previous weeks using the data type\n",
        "dictionary to map column names to column types; however, a more\n",
        "straightforward way to do this is to create different for loops for\n",
        "each.\n",
        "\n",
        "### 8.1 Profiling (Not Supported)\n",
        "\n",
        "> **Difficulty: Low.**\n",
        "\n",
        "The Pandas Profiling tool (rebranded a year or so back as\n",
        "[ydata-profiling](https://github.com/ydataai/ydata-profiling)) offers an\n",
        "alternative way of understanding whatâ€™s going on in your data. The\n",
        "output [looks rather nice](https://docs.profiling.ydata.ai/) and you\n",
        "might be tempted to ask why we didnâ€™t use this straight away on the full\n",
        "data set â€“ well, if you really want to know, see what happens when you\n",
        "profile all 70,000-odd rows and 70-odd columns in the raw data frameâ€¦ in\n",
        "effect: while itâ€™s â€˜nice to haveâ€™, the likelihood of crashing your\n",
        "computer increases significantly and itâ€™s a bit of a tangent, so thatâ€™s\n",
        "why itâ€™s no longer included in the Podman image.\n",
        "\n",
        "If you *do* want to explore this then youâ€™ll need to install the\n",
        "library, and **this is a good chance to look at how to install software\n",
        "on another machine**:"
      ],
      "id": "db4b6849-056e-428d-8dd3-04f5ffd22bf0"
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [],
      "source": [
        "from ydata_profiling import ProfileReport"
      ],
      "id": "0789d82c"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 8.2 Managing Memory\n",
        "\n",
        "> **Difficulty: Low.**\n",
        "\n",
        "So as to *why* youâ€™d want to fix your data types, there are two\n",
        "reasons: 1) to ensure that you can make the *most* of your data; 2) to\n",
        "ensure that it takes up as little space as possible in memory. Some\n",
        "simple examples:\n",
        "\n",
        "-   A column containing only the strings `'True'` (4 bytes) and\n",
        "    `'False'` (5 bytes) will take up vastly more space than a column\n",
        "    containing only `True` and `False` (1 **bit** each).\n",
        "-   A column containing only `'Red'`, `'Green'`, and `'Blue'` (3, 5, and\n",
        "    4 bytes each respectively) will take up much more space that a\n",
        "    column where we use the numbers `1, 2, 3` to represent these values\n",
        "    and have a map that tells us `1==Red`, `2==Blue`, and `3==Green`.\n",
        "\n",
        "Letâ€™s test this idea out before looking more closely at how to convert\n",
        "each type of data:"
      ],
      "id": "65e69f5a-9d39-4301-817b-d92b7a0e1d61"
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The raw memory usage of `room_type` is 5,741 Kb.\n",
            "The categorical memory usage of `room_type` is 729 Kb.\n",
            "That's 13% of the original!"
          ]
        }
      ],
      "source": [
        "# String type memory usage\n",
        "rtm = df.room_type.memory_usage(deep=True) \n",
        "# Categorical type memory usage\n",
        "ctm = df.room_type.astype('category').memory_usage(deep=True) \n",
        "\n",
        "print(f\"The raw memory usage of `room_type` is {rtm/1024:,.0f} Kb.\")\n",
        "print(f\"The categorical memory usage of `room_type` is {ctm/1024:,.0f} Kb.\")\n",
        "print(f\"That's {(ctm/rtm)*100:.0f}% of the original!\")"
      ],
      "id": "43848ab5"
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The raw memory usage of `host_is_superhost` is 4,686 Kb.\n",
            "The boolean memory usage of `host_is_superhost` is 728 Kb.\n",
            "That's 16% of the original!"
          ]
        }
      ],
      "source": [
        "# String type memory usage\n",
        "shm = df.host_is_superhost.memory_usage(deep=True) \n",
        "# Boolean type memory usage\n",
        "bhm = df.host_is_superhost.replace({'f':False, 't':True}).astype('bool').memory_usage(deep=True) \n",
        "\n",
        "print(f\"The raw memory usage of `host_is_superhost` is {shm/1024:,.0f} Kb.\")\n",
        "print(f\"The boolean memory usage of `host_is_superhost` is {bhm/1024:,.0f} Kb.\")\n",
        "print(f\"That's {(bhm/shm)*100:.0f}% of the original!\")"
      ],
      "id": "62b1620c"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 8.3 Boolean Values\n",
        "\n",
        "> **Difficulty: Moderate.**\n",
        "\n",
        "Letâ€™s start with columns that are likely to be boolean:"
      ],
      "id": "e06ed5ad-2fd8-4a6a-9b72-00fee0da92b4"
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {},
      "outputs": [
        {
          "output_type": "display_data",
          "metadata": {},
          "data": {
            "text/html": [
              "\n",
              "</div>"
            ]
          }
        }
      ],
      "source": [
        "bools = ['host_is_superhost']\n",
        "df.sample(5, random_state=43)[bools]"
      ],
      "id": "95e144ed"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Here we have to `map` â€˜tâ€™ to True and â€˜fâ€™ to False *before* converting\n",
        "the column to a boolean type. If you simply tried to replace them with\n",
        "the strings â€˜Trueâ€™ and â€˜Falseâ€™, then any string that is not `None` would\n",
        "convert to a `True` boolean."
      ],
      "id": "1ebba295-6662-4ee2-8efa-303364d5062c"
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Converting host_is_superhost"
          ]
        }
      ],
      "source": [
        "# This approach requires us to map 't' \n",
        "# and 'f' to True and False\n",
        "for b in bools:\n",
        "    print(f\"Converting {b}\")\n",
        "    df[b] = df[b].replace({'f':False, 't':True}).astype('bool')"
      ],
      "id": "0bcf3010"
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {},
      "outputs": [
        {
          "output_type": "display_data",
          "metadata": {},
          "data": {
            "text/html": [
              "\n",
              "</div>"
            ]
          }
        }
      ],
      "source": [
        "df.sample(5, random_state=43)[bools]"
      ],
      "id": "c98fb0eb"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 8.4 Dates\n",
        "\n",
        "> **Difficulty: Hard.**\n",
        "\n",
        "Iâ€™ve found dates to be particularly challenging, though pandas has\n",
        "*tried* to make this process less painful than it was a few years ago.\n",
        "What can be particularly frustrating is if *one* row has a non-sensical\n",
        "date value (e.g.Â a `t`, as happened in 2019/20) then the entire type\n",
        "conversion will fail. When that happens, pandas is not great about\n",
        "communicating where the problem occurred and I had to work it out by\n",
        "trying to convert *parts* of each series (using `.iloc`) to the datetime\n",
        "type until I had a block that failed. I then knew that I could narrow\n",
        "this down further using integer location indexing."
      ],
      "id": "c95d910b-ce73-405c-8d07-998fb25a325c"
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Currently host_since is of type 'object' \n"
          ]
        },
        {
          "output_type": "display_data",
          "metadata": {},
          "data": {
            "text/html": [
              "\n",
              "</div>"
            ]
          }
        }
      ],
      "source": [
        "dates = ['last_scraped','host_since','first_review','last_review']\n",
        "\n",
        "print(f\"Currently {dates[1]} is of type '{df[dates[1]].dtype}'\", \"\\n\")\n",
        "df.sample(5, random_state=43)[dates]"
      ],
      "id": "2ea304c0"
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Converting last_scraped\n",
            "Converting host_since\n",
            "Converting first_review\n",
            "Converting last_review"
          ]
        }
      ],
      "source": [
        "for d in dates:\n",
        "    print(\"Converting \" + d)\n",
        "    df[d] = pd.to_datetime(df[d])"
      ],
      "id": "0182466b"
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {},
      "outputs": [
        {
          "output_type": "display_data",
          "metadata": {},
          "data": {
            "text/html": [
              "\n",
              "</div>"
            ]
          }
        }
      ],
      "source": [
        "df.sample(5, random_state=43)[dates]"
      ],
      "id": "6d6abbd7"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Of course, itâ€™s not actually clear there what has changed! But if you\n",
        "dig a little more deeply:"
      ],
      "id": "dce79fed-ba50-40bb-8e06-2d3ba360bfe0"
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Now host_since is of type 'datetime64[ns]' \n"
          ]
        },
        {
          "output_type": "display_data",
          "metadata": {},
          "data": {
            "text/plain": [
              "90719      Tuesday August 25, 2015\n",
              "86895      Thursday April 04, 2024\n",
              "23856    Tuesday February 06, 2024\n",
              "11538      Monday October 14, 2019\n",
              "21073    Tuesday December 03, 2019\n",
              "Name: host_since, dtype: object"
            ]
          }
        }
      ],
      "source": [
        "print(f\"Now {dates[1]} is of type '{df[dates[1]].dtype}'\", \"\\n\")\n",
        "df.sample(5, random_state=45)[dates[1]].dt.strftime('%A %B %d, %Y')\n",
        "# Try some other formats!"
      ],
      "id": "a6f22d6e"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In that line of code we:\n",
        "\n",
        "-   Took a random sample (setting the state to 45),\n",
        "-   Took the second column from the dates list (`dates[1]`),\n",
        "-   Used the *date* â€˜accessor methodâ€™ (`.dt`),\n",
        "-   And called `string format time` with the format `%A %B %d, %Y` (Full\n",
        "    Day of Week, Month Name, Date, 4-digit Year)\n",
        "\n",
        "### 8.5 Categories\n",
        "\n",
        "> **Difficulty: Moderate.**\n",
        "\n",
        "We know that these are likely to be categories because thereâ€™d be no\n",
        "other way to allow users to effectively search Airbnb."
      ],
      "id": "a39a64f0-a4c0-4086-ab58-1fe30f20839e"
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Currently room_type is of type 'object' \n"
          ]
        },
        {
          "output_type": "display_data",
          "metadata": {},
          "data": {
            "text/html": [
              "\n",
              "</div>"
            ]
          }
        }
      ],
      "source": [
        "cats = ['property_type','room_type']\n",
        "\n",
        "print(f\"Currently {cats[1]} is of type '{df[cats[1]].dtype}'\", \"\\n\")\n",
        "df.sample(5, random_state=42)[cats]"
      ],
      "id": "139ad41b"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This next piece of code is quite useful for grouping and counting\n",
        "operations: we are counting the occurences of each unique value in part\n",
        "particular column or combination of columns:\n",
        "\n",
        "``` python\n",
        "df[cats[0]].value_counts()\n",
        "```\n",
        "\n",
        "    property_type\n",
        "    Entire rental unit              34289\n",
        "    Private room in rental unit     11681\n",
        "    Private room in home             9833\n",
        "    Entire condo                     8412\n",
        "    Entire home                      7437\n",
        "                                    ...  \n",
        "    Religious building                  1\n",
        "    Shared room in villa                1\n",
        "    Minsu                               1\n",
        "    Private room in nature lodge        1\n",
        "    Private room in floor               1\n",
        "    Name: count, Length: 94, dtype: int64\n",
        "\n",
        "``` python\n",
        "df[cats[1]].value_counts()\n",
        "```\n",
        "\n",
        "    room_type\n",
        "    Entire home/apt    54157\n",
        "    Private room       28197\n",
        "    Shared room          327\n",
        "    Hotel room           175\n",
        "    Name: count, dtype: int64\n",
        "\n",
        "> **Tip**\n",
        ">\n",
        "> One column has *many* different values (including Campers/RVs and\n",
        "> Yurts!), the other has just four. If I were looking to conduct\n",
        "> research Iâ€™d probably *start* with the `room_type` column since I may\n",
        "> not care about hotels and therefore never even need to decide whether\n",
        "> I care about boutique ones!"
      ],
      "id": "e94865c3-8e90-4f23-80f9-c42f635ed754"
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Converting property_type\n",
            "Converting room_type"
          ]
        }
      ],
      "source": [
        "for c in cats:\n",
        "    print(f\"Converting {c}\")\n",
        "    df[c] = df[c].astype('category')"
      ],
      "id": "e6ecaa91"
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Now room_type is of type 'category' \n",
            "\n",
            "['Entire home/apt' 'Hotel room' 'Private room' 'Shared room']"
          ]
        }
      ],
      "source": [
        "print(f\"Now {cats[1]} is of type '{df[cats[1]].dtype}'\", \"\\n\")\n",
        "print(df[cats[1]].cat.categories.values)"
      ],
      "id": "782056a0"
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {},
      "outputs": [
        {
          "output_type": "display_data",
          "metadata": {},
          "data": {
            "text/html": [
              "\n",
              "</div>"
            ]
          }
        }
      ],
      "source": [
        "df.sample(5, random_state=42)[cats]"
      ],
      "id": "24207a3e"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 8.6 Dealing with Strings\n",
        "\n",
        "> **Difficulty: Hard.**\n",
        "\n",
        "Weâ€™ll have to put some more work into dealing with the description and\n",
        "other â€˜free-fromâ€™ text fields later in the term, but for now letâ€™s just\n",
        "deal with a straightforward one: price!"
      ],
      "id": "72882615-8e40-455c-86e4-bfc43c7e1ec4"
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {},
      "outputs": [
        {
          "output_type": "display_data",
          "metadata": {},
          "data": {
            "text/html": [
              "\n",
              "</div>"
            ]
          }
        }
      ],
      "source": [
        "money = ['price']\n",
        "df.sample(5, random_state=42)[money]"
      ],
      "id": "bd739ab3"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**You will get an error when you run the next code block**, thatâ€™s\n",
        "because I want you to do a little thinking about how to extend the code\n",
        "to fix the data. Youâ€™ve already got the code you need to fix it, you\n",
        "just need to do a bit of thinking about â€˜method chainingâ€™!"
      ],
      "id": "e655c10a-2476-45e9-9ed7-4dc1bd539871"
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Converting price\n",
            "    xxxx Unable to convert price to float xxxx\n",
            "could not convert string to float: '1,000.00'"
          ]
        }
      ],
      "source": [
        "for m in money:\n",
        "    print(f\"Converting {m}\")\n",
        "    try:\n",
        "        df[m] = df[m].str.replace('$','', regex=False).astype('float')\n",
        "    except ValueError as e:\n",
        "        print(f\"    xxxx Unable to convert {m} to float xxxx\")\n",
        "        print(e)"
      ],
      "id": "8e8d3261"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Look closely at the error and then think about what you need to add to\n",
        "the code below:\n",
        "\n",
        "> **Note**\n",
        ">\n",
        "> For now donâ€™t worry about what `regex=False` means. It will all make\n",
        "> sense when we get to *dealing with text*.\n",
        "\n",
        "##### 8.6.0.1 Question"
      ],
      "id": "f7fee4ae-dae4-4fc0-b177-ecd6e5d9cecd"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for m in money:\n",
        "    print(f\"Converting {m}\")\n",
        "    df[m] = df[m].str.replace('$','', regex=False).str.replace(??).astype('float')"
      ],
      "id": "fbde1f4e-7334-4e62-a8e5-6cdebb8aba43"
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {},
      "outputs": [
        {
          "output_type": "display_data",
          "metadata": {},
          "data": {
            "text/html": [
              "\n",
              "</div>"
            ]
          }
        }
      ],
      "source": [
        "df.sample(5, random_state=42)[money]"
      ],
      "id": "c56b7dbc"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "And hereâ€™s a final thing to note that looksâ€¦ a little odd:"
      ],
      "id": "a7cb24c3-7c2c-43e7-b2cd-577bb5c53286"
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {},
      "outputs": [
        {
          "output_type": "display_data",
          "metadata": {},
          "data": {
            "text/html": [
              "\n",
              "</div>"
            ]
          }
        }
      ],
      "source": [
        "df.sort_values(by='price', ascending=False).head(5)[['id','name','price','minimum_nights']]"
      ],
      "id": "65248dae"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 8.7 Dealing with Integers\n",
        "\n",
        "> **Difficulty: Hard.**\n",
        "\n",
        "This is the issue that made me abandon the idea of making you clean the\n",
        "data yourselves. Although *floats* have no issues with `np.nan` in the\n",
        "Series, by default there are no numpy integer arrays that can cope with\n",
        "NaNs. This was such a major issue for Pandas that theyâ€™ve actually\n",
        "created their *own* data type that *does* support NaN values in integer\n",
        "columns. There are a lot of integer columns, but only one of them seems\n",
        "to be a problem."
      ],
      "id": "8bb2d669-d8e3-45e0-9db3-2149dec37cf1"
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Converting id\n",
            "Converting host_id\n",
            "Converting host_listings_count\n",
            "Converting host_total_listings_count\n",
            "Converting accommodates\n",
            "Converting beds\n",
            "  - !!!Converting to unsigned 16-bit integer!!!\n",
            "Converting minimum_nights\n",
            "Converting maximum_nights\n",
            "Converting availability_365"
          ]
        }
      ],
      "source": [
        "ints  = ['id','host_id','host_listings_count','host_total_listings_count','accommodates',\n",
        "         'beds','minimum_nights','maximum_nights','availability_365']\n",
        "for i in ints:\n",
        "    print(f\"Converting {i}\")\n",
        "    try:\n",
        "        df[i] = df[i].astype('float').astype('int')\n",
        "    except ValueError as e:\n",
        "        print(\"  - !!!Converting to unsigned 16-bit integer!!!\")\n",
        "        df[i] = df[i].astype('float').astype(pd.UInt16Dtype())"
      ],
      "id": "1808c0c3"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "So we convert the column but using a `try / except` approach that allows\n",
        "to trap `ValueError` exceptions triggered by the presence of NaNs in the\n",
        "column. The following code tells us that there are just eight of these\n",
        "in the 10k sample, but theyâ€™re enough to cause the code to fail if you\n",
        "donâ€™t trap them. The alternatives would be to: a) drop those rows; or b)\n",
        "leave the data as floats. For some reason the latter offends my sense of\n",
        "order, and the former feels like avoiding the problem rather than\n",
        "dealing with it."
      ],
      "id": "c74b0973-aea9-47b2-8b3c-40be4f0fd8af"
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {},
      "outputs": [
        {
          "output_type": "display_data",
          "metadata": {},
          "data": {
            "text/plain": [
              "beds\n",
              "False    60769\n",
              "True     22087\n",
              "Name: count, dtype: int64"
            ]
          }
        }
      ],
      "source": [
        "df.beds.isna().value_counts()"
      ],
      "id": "ff26bcaa"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 8.8 Validation\n",
        "\n",
        "> **Difficulty: Low.**\n",
        "\n",
        "Ordinarily, at this point I would then output information to confirm\n",
        "that all of the opeations I *think* Iâ€™ve undertaken were correctly\n",
        "applied."
      ],
      "id": "b059f51d-c764-4e93-a38d-bcf7d1b1c3f6"
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {},
      "outputs": [],
      "source": [
        "df.info()"
      ],
      "id": "0d1a3e40"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 8.9 Saving\n",
        "\n",
        "Also at this point I would save a copy of the cleaned data, though I\n",
        "would only consider this data *partially* cleaned since weâ€™ve not made\n",
        "it any further than just ensuring that each column is in an appropriate\n",
        "format and that some particularly problematic rows have been dropped!"
      ],
      "id": "5aaf846e-bda7-43f4-b792-320969260a22"
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved 82,856 rows of 32 columns to /home/jovyan/work/practicals/data/clean/20250615-London-listings.csv.gz\n",
            "Done."
          ]
        }
      ],
      "source": [
        "csv_out = Path(f'data/clean/{path.name}')\n",
        "pq_out  = Path(f'data/clean/{path.name.replace('.csv.gz','.parquet')}')\n",
        "\n",
        "if not csv_out.parent.exists():\n",
        "    print(f\"Creating {csv_out.parent}\")\n",
        "    csv_out.parent.mkdir(parents=True, exist_ok=True)\n",
        "    \n",
        "df.to_csv(csv_out, index=False)\n",
        "df.to_parquet(pq_out, index=False)\n",
        "print(f\"Saved {df.shape[0]:,} rows of {df.shape[1]:,} columns to {csv_out.resolve()}\")\n",
        "print(\"Done.\")"
      ],
      "id": "16289e52"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Weâ€™ll shortly begin to look at the `parquet` file format because itâ€™s\n",
        "fast, it preserves data types, itâ€™s compressed, and it will avoid the\n",
        "kinds of the problems that come up when you move to/from CSV as a\n",
        "default; however, for now letâ€™s keep working with what we understand.\n",
        "\n",
        "## 9. Selection using Criteria\n",
        "\n",
        "So far weâ€™ve been taking primarily a row and column view of the data,\n",
        "now we want to think more formally about selecting ranges from within\n",
        "the data setâ€¦\n",
        "\n",
        "### 9.1 Selecting using Data Types\n",
        "\n",
        "> **Difficulty: Low.**\n",
        "\n",
        "If we wanted to filter in/out certain columns pandas can do that! Letâ€™s\n",
        "try for floats and ints (*hint*: these are 64-bit data types).\n",
        "\n",
        "##### 9.1.0.1 Question"
      ],
      "id": "d50109f8-c381-412e-a9ac-4e9767e5f491"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df.select_dtypes(include=[??])"
      ],
      "id": "e192509d-8391-485d-8415-1a10e5b2713f"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 9.2 Selecting using Conditions\n",
        "\n",
        "> **Difficulty: Hard.**\n",
        "\n",
        "Conditional selection is usally done as a combination of the selection\n",
        "approaches above in combination with conditionals. So to try to select\n",
        "only the `Entire home/apt` room type we are testing for cases where the\n",
        "`room_type` equals our target term (`Entire home/apt`):\n",
        "\n",
        "##### 9.2.0.1 Question"
      ],
      "id": "a90cb47c-7ea2-4122-b77c-86d88fec9908"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df[df.??=='??']['property_type'].value_counts().head(10)"
      ],
      "id": "e83fb7f3-5bd6-44f3-8d21-19c971bc20ca"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Your output should be:"
      ],
      "id": "cd444742-ef8c-44f3-82f5-bbfc8eb93a59"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "property_type\n",
        "Entire rental unit           34289\n",
        "Entire condo                  8412\n",
        "Entire home                   7437\n",
        "Entire serviced apartment     1653\n",
        "Entire townhouse              1041\n",
        "Entire loft                    352\n",
        "Entire guesthouse              217\n",
        "Name: count, dtype: int64"
      ],
      "id": "417ee445-ee63-464a-98af-cd767f3f07aa"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 9.3 Arbitrary Selection Criteria\n",
        "\n",
        "> **Difficulty: Moderate, if the previous section made sense to you.**\n",
        "\n",
        "OK, now letâ€™s look for the Entire home/apt listings that cost more than\n",
        "the average price of all listingsâ€¦ to do *that* letâ€™s get a sense of\n",
        "where the mean and median value fall:\n",
        "\n",
        "##### 9.3.0.1 Question"
      ],
      "id": "bd746405-a196-4c7b-a31d-af3be215e430"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(f\"The mean price is ${df.price.??():0.2f}\")\n",
        "print(f\"The median price is ${df.price.??():0.2f}\")"
      ],
      "id": "b4851211-6cb8-467e-8c27-e17463a9b464"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "You should get:\n",
        "\n",
        "-   The mean price is \\$209.56\n",
        "-   The median price is \\$137.00\n",
        "\n",
        "You should see that the mean is higher than the median price but both\n",
        "are *very* roughly plausible values. Given your understanding of\n",
        "distributions from, say, Quantitative Methods, what can you say about\n",
        "the pricing distribution of Airbnb units?\n",
        "\n",
        "You might want to have a [look at the\n",
        "documentation](http://pandas.pydata.org/pandas-docs/stable/api.html#series):\n",
        "itâ€™s rather a long list, but most of your descriptive stats are on that\n",
        "page in the [Cumulative / Descriptive\n",
        "Stats](http://pandas.pydata.org/pandas-docs/stable/api.html#computations-descriptive-stats)\n",
        "section, and thereâ€™s also lots of information about methods for\n",
        "[strings](http://pandas.pydata.org/pandas-docs/stable/api.html#string-handling)\n",
        "and [categorical\n",
        "data](http://pandas.pydata.org/pandas-docs/stable/api.html#categorical).\n",
        "\n",
        "#### 9.3.1 Filtering: itâ€™s â€˜logicalâ€™\n",
        "\n",
        "So we want to take `Entire home/apt` and filter the data set *together\n",
        "with* the price per night from the `price` column. For that, letâ€™s use\n",
        "the mean price/night of \\$209.56. *Note*: this is totally arbitrary.\n",
        "\n",
        "##### 9.3.1.1 Question\n",
        "\n",
        "So here we want to filter on two values in the data set using `&`:"
      ],
      "id": "92909866-945e-42da-9963-aff5391ec711"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pricey = df[\n",
        "    (??) & \n",
        "    (df.price>df.price.??)\n",
        "]\n",
        "print(f\"Selected {pricey.shape[0]:,} rows\")"
      ],
      "id": "ef711f61-4e90-4909-a49e-e85f49e526fb"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "You should get 16,257 rows.\n",
        "\n",
        "In the code above we see two things:\n",
        "\n",
        "1.  The use of the bitwise `&` (itâ€™s *not* the same as `and` and you\n",
        "    should recall our work with the `bitarray` earlier in the term).\n",
        "2.  The fact that you need parentheses around the selection in order to\n",
        "    make the the `&` work.\n",
        "\n",
        "### 9.4 Selection with an Aggregate\n",
        "\n",
        "> **Difficulty: Low.**\n",
        "\n",
        "Letâ€™s find the cheapest and most expensive listings using `min` and\n",
        "`max` methods:\n",
        "\n",
        "##### 9.4.0.1 Question\n",
        "\n",
        "Least expensive:"
      ],
      "id": "7bc2a9d2-2899-4256-afd3-58ee5d7a25a3"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df[df.price==df.price.??()][['price','id','listing_url','room_type','description']]"
      ],
      "id": "932a0246-6c59-4511-84cc-27bac84a360b"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Most expensive:"
      ],
      "id": "a5ed52c9-93a0-4390-bca7-17e942141723"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df[df.price==df.price.??()][['price','id','listing_url','room_type','description']]"
      ],
      "id": "44379247-8593-40eb-94e2-838af34df476"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "You should see one or more units priced at exceedingly high levelsâ€¦ and\n",
        "hereâ€™s a way to see a few more of these budget-busting options."
      ],
      "id": "9621b968-8351-46b9-bb84-bf8e7471514d"
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {},
      "outputs": [
        {
          "output_type": "display_data",
          "metadata": {},
          "data": {
            "text/html": [
              "\n",
              "</div>"
            ]
          }
        }
      ],
      "source": [
        "df.sort_values(by='price', ascending=False).head(3)[\n",
        "    ['price','listing_url','room_type','description']\n",
        "]"
      ],
      "id": "0aaef995"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "> **Stop: Ask yourself if the result is *plausible*.**\n",
        "\n",
        "##### 9.4.0.2 Question\n",
        "\n",
        "What do you make of this result?\n",
        "\n",
        "### 9.5 Selection with a Range\n",
        "\n",
        "> **Difficulty: Moderate**\n",
        "\n",
        "Perhaps we arenâ€™t just looking for extremesâ€¦ how about all of the\n",
        "properties falling within the middle of the distribution? We can ask for\n",
        "any abitrary quantile we like, so letâ€™s go with the 25th and 75th\n",
        "percentile to get the middle 50% of the data. Google how to get\n",
        "percentiles from pandas.\n",
        "\n",
        "##### 9.5.0.1 Question"
      ],
      "id": "9490b35e-1b5e-4b16-8413-cf5fb9606f52"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dfr = df[ \n",
        "            (df.price > df.price.quantile(??)) & \n",
        "            (df.price < df.price.quantile(??)) ]\n",
        "\n",
        "print(f\"Lower Quartile: {df.price.quantile(??):>6.2f}\")\n",
        "print(f\"Upper Quartile: {df.price.quantile(??):>6.2f}\")\n",
        "print()\n",
        "print(f\"Range selected contains {dfr.shape[0]:,} rows.\")\n",
        "print(f\"Minimum price: {dfr.price.??():>6.2f}\")\n",
        "print(f\"Maximum price: {dfr.price.??():>6.2f}\")"
      ],
      "id": "0d65535d-eb3e-4c34-a222-aaf6bfca884a"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "That example contains a few things to which you need to pay attention:\n",
        "\n",
        "1.  *Again* you can see that, with mutiple selections, we had to put\n",
        "    parentheses around each one â€“ this forces Python toâ€¦\n",
        "2.  Process the `&` (bit-wise AND) that asks pandas to â€œFind all the\n",
        "    rows where condition 1 *AND* condition 2 are both `True`â€. So it\n",
        "    calculates the `True`/`False` for the left side and the\n",
        "    `True`/`False` for the right side of the `&`, and then combines\n",
        "    them.\n",
        "\n",
        "I find this parentheses business annoying and frequently get an error\n",
        "when I forget to add them, but Iâ€™m guessing itâ€™s tied to operator\n",
        "precedence and how the various operations are interpreted by Python.\n",
        "\n",
        "## 10. Deriving New Variables\n",
        "\n",
        "> **Difficulty: ðŸ¤¯**\n",
        "\n",
        "Letâ€™s try calculating several derived measures of distribution for the\n",
        "priceâ€¦ these deliberately demonstrate different ways of handling this\n",
        "process (and notice also the little call to `apply` that can perform\n",
        "additional tasks).\n",
        "\n",
        "#### 10.0.1 The *z*-Score\n",
        "\n",
        "The z-score is given by $z = (x - \\bar{x})/\\sigma$.\n",
        "\n",
        "##### 10.0.1.1 Question"
      ],
      "id": "8531063f-f37b-4c59-a816-d7488a72946c"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df['z'] = (df.?? - df.??.??()) / df.??.??()\n",
        "df.z.describe().apply(lambda x: f\"{x:5.5f}\")"
      ],
      "id": "274fa662-75c4-4d06-abbc-b56cdf80626e"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 10.0.2 Inter-Quartile Standardisation\n",
        "\n",
        "The IQR-standardised score is given by $i = (x - Q_{1})/(Q_{3} - Q_{1})$\n",
        "\n",
        "##### 10.0.2.1 Question"
      ],
      "id": "4f42d312-0c9e-461f-b670-f31713582aca"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df['iqs'] = (df.price - ??)/(??-??)\n",
        "df.iqs.describe().apply(lambda x: f\"{x:5.5f}\")"
      ],
      "id": "35dc30d8-3cb3-4a6e-b11a-783dfa156dae"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 10.0.3 Log-Normalisation\n",
        "\n",
        "The natural log of the price is gven by $ln(x)$\n",
        "\n",
        "##### 10.0.3.1 Question"
      ],
      "id": "b242110d-77ce-4606-abb6-50a8ba5e484d"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df['lnprice'] = np.log(??)\n",
        "df.lnprice.describe().apply(lambda x: f\"{x:5.5f}\")"
      ],
      "id": "ab1693a1-aaec-4ed7-a44f-08d2fe2867f2"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 11. Quick (and Dirty) Plotting\n",
        "\n",
        "Although weâ€™ve spent a lot of time grappling with pandas code and\n",
        "cleaning/filtering/selecting data, one of the first things we should\n",
        "really do when exploring a new dataset is plot (aka graph) the data.\n",
        "Weâ€™ve left plotting until late in this practical so that we could see\n",
        "some other basic attributes of how pandas stores data. Weâ€™ll look at\n",
        "plotting and exploratory data analyses in much more detail across the\n",
        "following weeks, including using packages other than pandas.\n",
        "\n",
        "For now, letâ€™s look at the basic plotting functionality pandas\n",
        "provides - in conjunctions with the online documentation for both\n",
        "[DataFrames](https://pandas.pydata.org/pandas-docs/stable/reference/index.html)\n",
        "and\n",
        "[Series](https://pandas.pydata.org/pandas-docs/stable/reference/index.html).\n",
        "There are also examples of all [the different types of plots pandas can\n",
        "produce](https://pandas.pydata.org/pandas-docs/stable/user_guide/visualization.html).\n",
        "\n",
        "> **MacOS plotting *without* Podman**\n",
        ">\n",
        "> MacOS users who are *not* using Podman will need to do certain things\n",
        "> in a specific order at the start of any notebook in order to show maps\n",
        "> or graphs. Please make a copy of the following code for any notebook\n",
        "> that you create and make it the *first* code that you run in the\n",
        "> notebookâ€¦\n",
        ">\n",
        "> ``` python\n",
        "> # Needed on a Mac\n",
        "> import matplotlib as mpl\n",
        "> mpl.use('TkAgg')\n",
        "> %matplotlib inline\n",
        "> import matplotlib.pyplot as plt\n",
        "> ```\n",
        "\n",
        "#### 11.0.1 Histograms\n",
        "\n",
        "> **Difficulty: Low**\n",
        "\n",
        "First, letâ€™s see some of the ways we could visualise the distribution of\n",
        "the `Series` in the dataset:"
      ],
      "id": "0d5ceef8-a09f-464d-8048-aeb3baf2f5b2"
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {},
      "outputs": [],
      "source": [
        "df.price.plot.hist() # histogram"
      ],
      "id": "762a06b9"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "If the code worked properly you should have just created a standard\n",
        "[histogram](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.plot.hist.html)\n",
        "plot (if you canâ€™t see one, ask for help). However, a basic problem here\n",
        "may be the range of the data: if your maximum price is much more than\n",
        "Â£5,000 then youâ€™ll find the majority of your data plotted in one bar,\n",
        "which isnâ€™t very helpful.\n",
        "\n",
        "You can filter the data *and* pass in some simple options to improve the\n",
        "plotting:"
      ],
      "id": "ca0109e4-4658-4bd6-851e-94603d680f29"
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Notice the ';' here to suppress `<AxesSubplot...>`\n",
        "# That information doesn't *always* appear, but whenever\n",
        "# you have unwanted textual output above your plot just\n",
        "# add a ';' on the end of the line of code!\n",
        "df[df.price < 1000].price.plot.hist(bins=50); "
      ],
      "id": "9f7ee079"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 11.0.2 KDE Plots\n",
        "\n",
        "> **Difficulty: Low**\n",
        "\n",
        "Similarly, we can produce a [Kernel Density Estimate\n",
        "plot](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.plot.kde.html).\n",
        "This time, instead of dropping data just before calling `plot` weâ€™re\n",
        "going to modify the *limits* of the x-axis using `xlim`:\n",
        "\n",
        "##### 11.0.2.1 Question\n",
        "\n",
        "Look for information about using `xlim`:"
      ],
      "id": "a8941395-9da9-4fe7-9de0-ffead3249ecf"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df.price.plot.kde(xlim=(??)); #kernel density estimate plot"
      ],
      "id": "75a21346-3b9c-4b83-b0a1-8b9201c8fe1a"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Kind of handy, no? These arenâ€™t the *best* looking plots, but they are\n",
        "all being generated on-the-fly for you by pandas with no more than a\n",
        "cheery `DataFrame.Series.plot.<plot type>`! Since those plots are all\n",
        "just method calls, many of them take optional parameters to change the\n",
        "colour, the notation (scientific or not), and other options. For\n",
        "example, many of the documentation pages linked to above are rather\n",
        "brief, but include a link to [the general options that can be applied to\n",
        "all\n",
        "`Series.plot`](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.plot.html)\n",
        "calls.\n",
        "\n",
        "This is why we like pandas: it allows us to be *constructively lazy*. We\n",
        "donâ€™t need to know *how* a draw a KDE plot (though it always helps if\n",
        "you donâ€™t see what you expected), we just need to know that pandas\n",
        "provides a method that will do it for you. And *that* is why itâ€™s always\n",
        "worth having a [look at the\n",
        "documentation](https://pandas.pydata.org/pandas-docs/stable/reference/index.html).\n",
        "\n",
        "#### 11.0.3 A Slight Case of Over-Plotting\n",
        "\n",
        "Generally, Jupyter is clever enough to overlay plots one on top of the\n",
        "other if you call them all in the same cell. Weâ€™ll see ways to gain more\n",
        "control later, but this is still a good start! Note that here we also\n",
        "need to get rid of the `-inf` values from rows that had a price of Â£0.\n",
        "\n",
        "> **Bug Alert**\n",
        ">\n",
        "> The more we use pandas to sort and filter data the more you will start\n",
        "> to see a `SettingWithCopyWarning`. This happens because of an\n",
        "> interaction between how Pandas works and how Python works: when you\n",
        "> are working with a very large data set you donâ€™t want to make a â€˜deep\n",
        "> copyâ€™ of the data structure every time you make a change to the data.\n",
        "> Instead, you get a â€˜viewâ€™ into the data using a reference, which is a\n",
        "> just a lightweight shortcut. So what happens when you try to modify\n",
        "> that lightweight copy? Well, if you want to drop rows or columns then\n",
        "> you either want to make a `copy()` at that point, or you will have to\n",
        "> accept the warning *and* the computational risks that go with it."
      ],
      "id": "fda8c66b-23e2-4b1d-9d29-bc063c5a31d5"
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Calling copy() ensures the index is updated\n",
        "# and note that all subsequent plots will have\n",
        "# these Â£0 rows removed!\n",
        "df = df[df.price > 0].copy() \n",
        "df.z.plot.kde(xlim=[-2, 10])\n",
        "df.iqs.plot.kde(xlim=[-2, 10])\n",
        "df.lnprice.plot.kde();"
      ],
      "id": "ca4d1175"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 11.0.4 Boxplots\n",
        "\n",
        "> **Difficulty: Low**\n",
        "\n",
        "A standard\n",
        "[boxplot](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.plot.box.html):"
      ],
      "id": "810bd165-dcc2-409d-8bf6-85ffa722077f"
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "metadata": {},
      "outputs": [],
      "source": [
        "df.lnprice.plot.box(figsize=(4, 8));"
      ],
      "id": "74fed464"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 11.0.5 Scatterplots\n",
        "\n",
        "> **Difficulty: Low**\n",
        "\n",
        "We can also plot two variables in a [scatter\n",
        "plot](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.plot.scatter.html#pandas.DataFrame.plot.scatter)\n",
        "by applying a plot method to the `DataFrame` (not an individual\n",
        "`Series`):"
      ],
      "id": "8d49debb-e9b6-4345-87f6-4ac2bd4e6257"
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "metadata": {},
      "outputs": [],
      "source": [
        "df.plot.scatter(x='longitude', y='latitude', c='price', s=2, cmap='viridis', figsize=(15,10))"
      ],
      "id": "7d0b9a92"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Note how the code above has the form `DataFrame.plot.<plot type>`, not\n",
        "`DataFrame.Series.plot.<plot type>` as in the prior plots. Think about\n",
        "why this then means we need the `x` and `y` arguments.\n",
        "\n",
        "Looking at the plot produced, itâ€™s hard to see where the high values\n",
        "are, so we might want to think about ways that we could make it easier\n",
        "to spot the big numbersâ€¦ We could, for instance, also vary the size of\n",
        "the point in a plot by some variable, but why does the following not\n",
        "really work?"
      ],
      "id": "c7e5cd2c-ba5b-4e47-9ffa-0265ae64d588"
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "metadata": {},
      "outputs": [],
      "source": [
        "df.plot.scatter(x='longitude', y='latitude', c='price', s=(df.price/df.price.min()), cmap='viridis', figsize=(15,10))"
      ],
      "id": "13c95710"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "And we can plot subsets of our data without creating a new object. See\n",
        "if you can work out what the following code is doing that is different\n",
        "from the last plot:"
      ],
      "id": "99bccd5a-dd04-44d2-940c-92f3c47deaaa"
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "metadata": {},
      "outputs": [],
      "source": [
        "df[df.price > df.price.quantile(0.90)].plot.scatter(x='longitude', y='latitude', c='price', cmap='viridis', s=8)"
      ],
      "id": "63ccafe4"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 11.0.6 Hex Bin Plots\n",
        "\n",
        "> **Difficulty: Low**\n",
        "\n",
        "And pandas allows us to create â€˜less standardâ€™ plots, like a [hex bin\n",
        "plot](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.plot.hexbin.html#pandas.DataFrame.plot.hexbin):"
      ],
      "id": "4fed10b3-5e02-49f7-95dd-805dc7214519"
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "metadata": {},
      "outputs": [],
      "source": [
        "df.plot.hexbin(x='longitude', y='latitude', gridsize=50, figsize=(10,7))"
      ],
      "id": "236e7164"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Thatâ€™s just a taste of what the basic plotting functionality of pandas\n",
        "can do. Feel free to explore more yourself and weâ€™ll also see [the\n",
        "seaborn package](http://seaborn.pydata.org/index.html) later.\n",
        "\n",
        "## 12. Credits!\n",
        "\n",
        "##### 12.0.0.1 License\n",
        "\n",
        "These teaching materials are licensed under a mix of [The MIT\n",
        "License](https://opensource.org/licenses/mit-license.php) and the\n",
        "[Creative Commons Attribution-NonCommercial-ShareAlike 4.0\n",
        "license](https://creativecommons.org/licenses/by-nc-sa/4.0/).\n",
        "\n",
        "##### 12.0.0.2 Acknowledgements:\n",
        "\n",
        "Supported by the [Royal Geographical\n",
        "Society](https://www.rgs.org/HomePage.htm) (with the Institute of\n",
        "British Geographers) with a Ray Y Gildea Jr Award.\n",
        "\n",
        "##### 12.0.0.3 Potential Dependencies:\n",
        "\n",
        "This notebook may depend on the following libraries: pandas, matplotlib"
      ],
      "id": "1f9e662c-0dcb-41b6-897a-cae271ac43c8"
    }
  ],
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "path": "/opt/conda/share/jupyter/kernels/python3"
    }
  }
}